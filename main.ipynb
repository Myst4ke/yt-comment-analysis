{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YT Comments analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from api import API_KEY\n",
    "\n",
    "channel_id = \"UCWeg2Pkate69NFdBeuRFTAw\" #Squeezie channel\n",
    "etoiles = 'UCABf02qOye7XYapcK1M45LQ'\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "exemple_video = \"qCKyRhkhqoQ\"\n",
    "otp_recap = 'F7A8OCdmZ90'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Request:\n",
    "    \"\"\" Class Request handling youtube request better \"\"\"\n",
    "    def __init__(self, requestType,part=None, id=None, chart=None, regionCode=None, maxResults=None, pageToken=None, videoId=None):\n",
    "        self.requestType = requestType\n",
    "        self.part = part\n",
    "        self.id = id\n",
    "        self.chart = chart\n",
    "        self.regionCode = regionCode\n",
    "        self.maxResults = maxResults\n",
    "        self.pageToken = pageToken\n",
    "        self.videoId = videoId\n",
    "        \n",
    "    def execute(self):\n",
    "        param = vars(self) # Fetch class attributes\n",
    "        param = {x:y for x,y in list(param.items())[1:] if y} # Delete requestType ([1:]) and None attributes\n",
    "        \n",
    "        request = self.requestType.list(**param)\n",
    "        return request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re      \n",
    "        \n",
    "def iso_toDatetime(iso_date:str):\n",
    "    \"\"\"Converts an ISO 8601 formatted date to a datetime object.\"\"\"\n",
    "    return datetime.strptime(iso_date[:-1], '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "def datetime_toISO(dt_obj:datetime):\n",
    "    \"\"\"Converts a datetime object to an ISO 8601 formatted date.\"\"\"\n",
    "    return dt_obj.isoformat()[:-7]  # remove microseconds\n",
    "\n",
    "def iso_toDelta(iso_duration:str):\n",
    "    \"\"\"Converts an ISO 8601 formatted duration to a timedelta object.\"\"\"\n",
    "    match = re.match(r'PT(\\d+D)*(\\d+H)*(\\d+M)*(\\d+S)', iso_duration)\n",
    "    days, hours, minutes, seconds = [int(x[:-1]) if x else 0 for x in match.groups()]\n",
    "    return timedelta(days=days,hours=hours, minutes=minutes, seconds=seconds)\n",
    "\n",
    "def delta_toISO(delta_obj:timedelta):\n",
    "    \"\"\"Converts a timedelta object to an ISO 8601 formatted duration.\"\"\"\n",
    "    hours = delta_obj.seconds // 3600\n",
    "    minutes = (delta_obj.seconds % 3600) // 60\n",
    "    seconds = delta_obj.seconds % 60\n",
    "    \n",
    "    daysStr = f\"{delta_obj.days}D\" if delta_obj.days != 0 else \"\"\n",
    "    hoursStr = f\"{hours}H\" if hours != 0 else \"\"\n",
    "    minutesStr = f\"{minutes}M\" if minutes != 0 else \"\"\n",
    "    secondsStr = f\"{seconds}S\" if seconds != 0 else \"\"\n",
    "    return f\"PT{daysStr}{hoursStr}{minutesStr}{secondsStr}\"\n",
    "\n",
    "# print(iso_toDelta('PT4D3H20M9S'))\n",
    "# print(delta_toISO(iso_toDelta('PT20M9S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_channel_data(channel_data):\n",
    "    \"\"\" Structure raw channel data \"\"\"\n",
    "    data = {\n",
    "        \"channel_name\": channel_data.get('snippet', {}).get('title'),\n",
    "        \"channel_id\": channel_data.get('id'),\n",
    "        \"country\": channel_data.get('snippet', {}).get('country',\"\"),\n",
    "        \"stats\": channel_data.get('statistics'),\n",
    "        \"topics\": [wikilink.split('/')[-1] for wikilink in channel_data.get('topicDetails', {}).get('topicCategories', [])],\n",
    "    }\n",
    "    del data['stats']['hiddenSubscriberCount']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(youtube, channel_id):\n",
    "    \"\"\" Request (by id) for most important channel stats \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.channels(),\n",
    "        part=\"snippet,contentDetails,statistics,topicDetails\",\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    rawData = response.get('items', [])[0]\n",
    "    return format_channel_data(rawData)\n",
    "    \n",
    "\n",
    "get_channel_data(youtube, channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def format_video_data(video_data):\n",
    "    \"\"\" Structure raw video data \"\"\"\n",
    "    data = {\n",
    "            \"title\": video_data.get('snippet', {}).get('title'),\n",
    "            \"id\": video_data.get('id'),\n",
    "            \"publishedAt\": video_data.get('snippet', {}).get('publishedAt'),\n",
    "            \"duration\" : video_data.get('contentDetails').get('duration'),\n",
    "            \"ViewCount\" : video_data.get('statistics', {}).get('viewCount'),\n",
    "            \"likeCount\" : video_data.get('statistics', {}).get('likeCount'),\n",
    "            \"commentCount\" : video_data.get('statistics', {}).get('commentCount'),  \n",
    "            \"tags\" : video_data.get('snippet', {}).get('tags')\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# time = get_video_info(youtube, 'JRBGBjaR9Wg').get(\"publishedAt\")\n",
    "# print(datetime.strptime(time, '%Y-%m-%dT%H:%M:%SZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(youtube, video_Id):\n",
    "    \"\"\" Request (by id) for most important video stats \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.videos(),\n",
    "        part=\"snippet,contentDetails,statistics,topicDetails\",\n",
    "        id=video_Id,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    rawData = response.get('items', [])[0]\n",
    "    return format_video_data(rawData)\n",
    "\n",
    "get_video_data(youtube, 'JRBGBjaR9Wg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Most_Popular_Video(youtube, region:str):\n",
    "    \"\"\" Request for most populars videos stats \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.videos(),\n",
    "        part=\"snippet,contentDetails,statistics,topicDetails\",\n",
    "        chart=\"mostPopular\",\n",
    "        regionCode=region,\n",
    "        maxResults=100,\n",
    "        pageToken=''\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    pages = [response]\n",
    "    while response.get('nextPageToken'):\n",
    "        request.pageToken = response.get('nextPageToken')\n",
    "        response = request.execute()\n",
    "        pages.append(response)\n",
    "    \n",
    "    top_videos = [format_video_data(videos) for page in pages for videos in page.get('items')]\n",
    "    return top_videos\n",
    "\n",
    "get_Most_Popular_Video(youtube, 'FR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_comment_data(comment):\n",
    "    \"\"\" Structure raw comment data \"\"\"\n",
    "    data = {\n",
    "        \"id\": comment.get('id'),\n",
    "        \"comment\": comment.get('snippet', {}).get('textOriginal'),\n",
    "        # \"viewerRating\": comment.get('snippet', {}).get('viewerRating'),\n",
    "        \"likeCount\": comment.get('snippet', {}).get('likeCount'),\n",
    "        \"publishedAt\": comment.get('snippet', {}).get('publishedAt'),\n",
    "        \"updatedAt\": comment.get('snippet', {}).get('updatedAt')\n",
    "        }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def format_threadedComment_data(comment):\n",
    "    \"\"\" Structure raw threaded comment data \"\"\"\n",
    "    data = {\n",
    "        \"id\": comment.get('id'),\n",
    "        \"topLevelComment\": format_comment_data(comment.get('snippet', {}).get('topLevelComment')),\n",
    "        \"totalReplyCount\": comment.get('snippet', {}).get('totalReplyCount'),\n",
    "        \"replies\": [format_comment_data(com) for com in comment.get('replies', {}).get('comments', [])]\n",
    "        }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(youtube,comment_id):\n",
    "    \"\"\" Request (by id) for most important comment stats \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.comments(),\n",
    "        part=\"snippet,id\",\n",
    "        id=comment_id,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    # print(response)\n",
    "    rawData = response.get('items')[0]\n",
    "    return format_comment_data(rawData)\n",
    "\n",
    "get_comment(youtube, 'UgwUQR2JJFJSkihWLhx4AaABAg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_commentThreads(youtube,video_Id):\n",
    "    \"\"\" Request (by id) for all comments of a videos \"\"\"\n",
    "    request = Request(\n",
    "        requestType=youtube.commentThreads(),\n",
    "        part=\"snippet,id,replies\",\n",
    "        videoId=video_Id,\n",
    "        maxResults=100,\n",
    "        pageToken = ''\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    pages = [response]\n",
    "    while response.get('nextPageToken'):\n",
    "        request.pageToken = response.get('nextPageToken')\n",
    "        response = request.execute()\n",
    "        pages.append(response)\n",
    "        \n",
    "    top_videos = [format_threadedComment_data(comments) for page in pages for comments in page.get('items')]\n",
    "    return top_videos\n",
    "\n",
    "get_video_commentThreads(youtube, otp_recap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Top Videos\n",
    "The goal is to fetch the top 200 videos everyday and to get their comments a week after publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "REGION = ['FR', 'US', 'GB']\n",
    "topvids = 'db/topVideos.json'\n",
    "minElapsedTime = 24 # Hours\n",
    "\n",
    "def push_top_vids(filepath):\n",
    "    today = datetime.today()\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    if lastUpdate:= data.get('lastUpdate'):\n",
    "        delta = today - iso_toDatetime(lastUpdate)\n",
    "        if delta.seconds // 3600 <= minElapsedTime:\n",
    "            raise Exception(f'The fetch request has be done too soon. Next request vailable in {24-(delta.seconds // 3600)}h ')\n",
    "    else:   \n",
    "        data['lastUpdate'] = datetime_toISO(today)\n",
    "        # Fetching\n",
    "        for reg in REGION:\n",
    "            if reg not in data.keys():\n",
    "                data[reg] = {}\n",
    "            data[reg][datetime_toISO(datetime.today())] = get_Most_Popular_Video(youtube, reg)\n",
    "\n",
    "        with open(filepath, 'w') as fichier:\n",
    "            json.dump(data, fichier)\n",
    "\n",
    "push_top_vids(topvids)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvids = 'db/topVideos.json'\n",
    "minElapsedComments = 7 # days\n",
    "\n",
    "def fetch_topVids_comments(filepath):\n",
    "    today = datetime.today()\n",
    "    with open(filepath, 'r') as f:\n",
    "        data:dict = json.load(f)\n",
    "        \n",
    "    del data['lastUpdate']\n",
    "    # print(data)\n",
    "    \n",
    "    for dailyEntries in data.values():\n",
    "        for vids in dailyEntries.values():\n",
    "            for video in vids:\n",
    "                if (today - iso_toDatetime(video.get('publishedAt'))).days >= minElapsedComments:\n",
    "                    if not video.get(\"fetchedComment\"):\n",
    "                        video['comments'] = get_video_commentThreads(youtube, video.get('id'))\n",
    "                        video['fetchedComment'] = True\n",
    "                        \n",
    "    with open(filepath, 'w') as fichier:\n",
    "            json.dump(data, fichier)                \n",
    "\n",
    "fetch_topVids_comments(topvids)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
